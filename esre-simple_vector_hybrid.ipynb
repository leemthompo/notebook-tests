{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Search using ELSER and Python\n",
        "\n",
        "In this example we'll use several different search techniques to compare the relevance of results for a given query.\n",
        "This will demonstrate the comparative advantages of full text search, [Elastic Learned Sparse Encoder](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-elser.html)-enabled semantic search, and hybrid search using the RRF rank aggregation method.\n",
        "\n",
        "> ‚ÑπÔ∏è We're using an interactive notebook, that allows you to run the code snippets in the browser and see the results in real time.\n",
        "You don't have to worry about setting up a Python environment locally or managing dependencies across different Python versions.\n",
        "\n",
        "\n",
        "`TODO: Preparing the Data: Discuss the data set you are using. Explain why this data set is appropriate for your experiment. Show how to import this data into your Elasticsearch instance.`"
      ],
      "metadata": {
        "id": "s49gpkvZ7q53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß∞ Requirements\n",
        "\n",
        "For this example, you will need:\n",
        "\n",
        "- Python 3.6 or later\n",
        "- An Elastic deployment with minimum **4GB machine learning node**\n",
        "   - We'll be using [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html) for this example (available with a [free trial](https://cloud.elastic.co/registration?elektra=en-ess-sign-up-page))\n",
        "- The [ELSER](https://www.elastic.co/guide/en/machine-learning/8.8/ml-nlp-elser.html) model installed on your Elastic deployment\n",
        "- The [Elastic Python client](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/installation.html)\n"
      ],
      "metadata": {
        "id": "Y01AXpELkygt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Elastic Cloud deployment\n",
        "\n",
        "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?fromURI=%2Fhome) for a free trial.\n",
        "\n",
        "- Go to the [Create deployment](https://cloud.elastic.co/deployments/create) page\n",
        "   - Under **Advanced settings**, go to **Machine Learning instances**\n",
        "   - You'll need at least **4GB** RAM per zone for this tutorial\n",
        "   - Select **Create deployment**"
      ],
      "metadata": {
        "id": "N4pI1-eIvWrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup ELSER\n",
        "To use ELSER, you must have the [appropriate subscription]() level\n",
        "for semantic search or the trial period activated.\n",
        "\n",
        "Follow these [instructions](https://www.elastic.co/guide/en/machine-learning/8.8/ml-nlp-elser.html#trained-model) to download and deploy ELSER in the Kibana UI or using the Dev Tools **Console**."
      ],
      "metadata": {
        "id": "nSw1R8e28F_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages and initialize the Elasticsearch Python client\n",
        "\n",
        "To get started, we'll need to connect to our Elastic deployment using the Python client.\n",
        "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
        "\n",
        "First we need to `pip` install the following packages:\n",
        "\n",
        "- `elasticsearch`\n"
      ],
      "metadata": {
        "id": "gaTFHLJC-Mgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install elasticsearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Q1p2C9-wce",
        "outputId": "204d5aee-571e-4363-be6e-f87d058f2d29"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting elasticsearch\n",
            "  Downloading elasticsearch-8.8.0-py3-none-any.whl (393 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m393.8/393.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elastic-transport<9,>=8 (from elasticsearch)\n",
            "  Downloading elastic_transport-8.4.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2022.12.7)\n",
            "Installing collected packages: elastic-transport, elasticsearch\n",
            "Successfully installed elastic-transport-8.4.0 elasticsearch-8.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[TODO: Update]\n",
        "Next we need to import the `elasticsearch` module and the `getpass` module.\n",
        "`getpass` is part of the Python standard library and is used to securely prompt for credentials."
      ],
      "metadata": {
        "id": "gEzq2Z1wBs3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from elasticsearch import Elasticsearch, helpers\n",
        "from urllib.request import urlopen\n",
        "import getpass\n",
        "import requests\n",
        "import json"
      ],
      "metadata": {
        "id": "uP_GTVRi-d96"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can instantiate the Python Elasticsearch client.\n",
        "First we prompt the user for their password and Cloud ID.\n",
        "\n",
        "üîê NOTE: `getpass` enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory.\n",
        "\n",
        "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class."
      ],
      "metadata": {
        "id": "AMSePFiZCRqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Found in the 'Manage Deployment' page\n",
        "CLOUD_ID = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
        "\n",
        "# Password for the 'elastic' user generated by Elasticsearch\n",
        "ELASTIC_PASSWORD = getpass.getpass('Enter Elastic password:  ')\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    cloud_id=CLOUD_ID,\n",
        "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0MdAZ53CdKL",
        "outputId": "96ea6f81-f935-4d51-c4a7-af5a896180f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Elastic Cloud ID:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter Elastic password:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirm that the client has connected with this test"
      ],
      "metadata": {
        "id": "bRHbecNeEDL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(client.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdiUKqZbEKfF",
        "outputId": "43b6f1cd-a43e-4dbe-caa5-7fd170464881"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'instance-0000000001', 'cluster_name': '4a73f876a51542b4bc743285bccff0ce', 'cluster_uuid': 'afW-XuQGSxyXB9TYzmr4ZA', 'version': {'number': '8.9.0-SNAPSHOT', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'ffb140d260b71a13ef323aa38aea7c5158c05a77', 'build_date': '2023-06-13T11:57:12.611577314Z', 'build_snapshot': True, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect to a self-managed deployment.\n",
        "\n",
        "Read https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect using API keys.\n"
      ],
      "metadata": {
        "id": "enHQuT57DhD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Elasticsearch index with required mappings\n",
        "\n",
        "To use the ELSER model at index time, we'll need to create an index mapping that supports a [`text_expansion`](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-text-expansion-query.html) query.\n",
        "The mapping must include a field of type [`rank_features`](https://www.elastic.co/guide/en/elasticsearch/reference/current/rank-features.html) to work with our feature vectors of interest.\n",
        "This field contains the token-weight pairs the ELSER model created based on the input text.\n",
        "\n",
        "Let's create an index named `elser-movies` with the mappings we need.\n"
      ],
      "metadata": {
        "id": "TF_wxIAhD07a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INDEX = 'elser-movies'\n",
        "client.indices.create(\n",
        "            index=INDEX,\n",
        "            settings={\n",
        "                \"index\": {\n",
        "                    \"number_of_shards\": 1,\n",
        "                    \"number_of_replicas\": 1\n",
        "                }\n",
        "            },\n",
        "            mappings={\n",
        "    \"properties\": {\n",
        "      \"genre\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"keyScene\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"plot\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"released\": {\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"runtime\": {\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"title\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"ml.tokens\": {\n",
        "        \"type\": \"rank_features\"\n",
        "      },\n",
        "      \"keyScene\": {\n",
        "        \"type\": \"text\"\n",
        "      }\n",
        "  }\n",
        "}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvYECABJJs_2",
        "outputId": "18fb51e4-c4f6-4d1b-cb2d-bc6f8ec1aa84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'elser-movies'})"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ohcvdngCGJlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an ingest pipeline with an inference processor to use ELSER\n",
        "\n",
        "In order to use ELSER on our Elastic Cloud deployment we'll need to create an ingest pipeline that contains an inference processor that runs the ELSER model.\n",
        "Let's add that pipeline using the [`put_pipeline`](https://www.elastic.co/guide/en/elasticsearch/reference/master/put-pipeline-api.html) method."
      ],
      "metadata": {
        "id": "EmELvr_JK_22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "client.ingest.put_pipeline(id=\"elser-v1-test\", body={\n",
        "    \"processors\": [\n",
        "    {\n",
        "      \"inference\": {\n",
        "        \"model_id\": \".elser_model_1\",\n",
        "        \"target_field\": \"ml\",\n",
        "        \"field_map\": {\n",
        "          \"keyScene\": \"text_field\",\n",
        "          \"plot\": \"text_field\"\n",
        "        },\n",
        "        \"inference_config\": {\n",
        "          \"text_expansion\": {\n",
        "            \"results_field\": \"tokens\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhRng99KLQsd",
        "outputId": "00ea73b5-45a4-472b-f4bc-2c2c790ab94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-139dc28db0d7>:1: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
            "  client.ingest.put_pipeline(id=\"elser-v1-test\", body={\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's note a few important parameters from that API call:\n",
        "\n",
        "- `inference`: A processor that performs inference using a machine learning model.\n",
        "- `model_id`: Specifies the ID of the machine learning model to be used. In this example, the model ID is set to `.elser_model_1`.\n",
        "- `target_field`: Defines the field where the inference result will be stored. Here, it is set to `ml`.\n",
        "- `text_expansion`: Configures text expansion options for the inference process.\n",
        "In this example, the inference results will be stored in a field named \"tokens\"."
      ],
      "metadata": {
        "id": "0wCH7YHLNW3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WgWDMgf9NkHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create index and mapping for test data\n",
        "\n",
        "\n",
        "We have some test data in a `json` file at this [URL](https://raw.githubusercontent.com/leemthompo/notebook-tests/main/12-movies.json).\n",
        "Let's load that into our Elastic deployment.\n",
        "First we'll create an index named `search-movies` to store that data."
      ],
      "metadata": {
        "id": "U3vT2g5LVIQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.indices.create(\n",
        "    index=\"search-movies\",\n",
        "    mappings= {\n",
        "    \"properties\": {\n",
        "      \"genre\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"keyScene\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"plot\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"released\": {\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"runtime\": {\n",
        "        \"type\": \"integer\"\n",
        "      },\n",
        "      \"title\": {\n",
        "        \"type\": \"text\",\n",
        "        \"fields\": {\n",
        "          \"keyword\": {\n",
        "            \"type\": \"keyword\",\n",
        "            \"ignore_above\": 256\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3ONJckPnUIT",
        "outputId": "07ea0766-c226-4510-c910-893db89757ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'search-movies'})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload sample data\n",
        "\n",
        "> ‚ö† To use the UI to upload data, follow the approach described [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/semantic-search-elser.html#load-data).\n",
        "\n",
        "Let's upload the JSON data.\n",
        "The dataset provides information on twelve iconic films.\n",
        "Each film's entry includes its title, runtime, plot summary, a key scene, genre classification, and release year."
      ],
      "metadata": {
        "id": "lFHgRUYVpNKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/leemthompo/notebook-tests/main/12-movies.json\"\n",
        "\n",
        "# Send a request to the URL and get the response\n",
        "response = urlopen(url)\n",
        "\n",
        "# Load the response data into a JSON object\n",
        "data_json = json.loads(response.read())\n",
        "\n",
        "def create_index_body(doc):\n",
        "    \"\"\" Generate the body for an Elasticsearch document. \"\"\"\n",
        "    return {\n",
        "        \"_index\": \"search-movies\",\n",
        "        \"_source\": doc,\n",
        "    }\n",
        "\n",
        "# Prepare the documents to be indexed\n",
        "documents = [create_index_body(doc) for doc in data_json]\n",
        "\n",
        "# Use helpers.bulk to index\n",
        "helpers.bulk(client, documents)\n",
        "\n",
        "print(\"Done indexing documents into `search-movies` index!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBfqgdAcuKRG",
        "outputId": "3b86daa1-ade1-4ff3-da81-4207fa814d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done indexing documents into `search-movies` index!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ingest the data through the inference ingest pipeline\n",
        "\n",
        "Create tokens from the text by reindexing the data throught the inference pipeline that uses ELSER as the inference model."
      ],
      "metadata": {
        "id": "73d3Td-1ubhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.reindex(wait_for_completion=False,\n",
        "               source={\n",
        "                  \"index\": \"search-movies\"\n",
        "    },\n",
        "               dest= {\n",
        "                  \"index\": \"elser-movies\",\n",
        "                  \"pipeline\": \"elser-v1-test\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysYobyC9uhn5",
        "outputId": "27af8c88-9039-4ff8-a20f-9af9ffcff05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'task': '8xcAx0HETC-KZXwVkVOBhw:10309989'})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confirm documents are indexed with additional fields\n",
        "\n",
        "A successful API call in the previous step returns a task ID to monitor the job's progress.\n",
        "Use the [task management API](https://www.elastic.co/guide/en/elasticsearch/reference/current/tasks.html) to check progress.\n",
        "You can also monitor this task using the **Trained Models** UI in Kibana, selecting the **Pipelines** tab under **ELSER**.\n",
        "\n",
        "Call the following, replacing `<task_id>` with the task id returned in the previous step."
      ],
      "metadata": {
        "id": "tUDGeY7e2-I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.tasks.get(task_id='8xcAx0HETC-KZXwVkVOBhw:10309989')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KXeXCc63WVw",
        "outputId": "e8fee6dd-34a1-401d-c879-71fd54de3c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ObjectApiResponse({'completed': True, 'task': {'node': '8xcAx0HETC-KZXwVkVOBhw', 'id': 10309989, 'type': 'transport', 'action': 'indices:data/write/reindex', 'status': {'total': 12, 'updated': 0, 'created': 12, 'deleted': 0, 'batches': 1, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0}, 'description': 'reindex from [search-movies] to [elser-movies]', 'start_time_in_millis': 1687255753693, 'running_time_in_nanos': 116833041, 'cancellable': True, 'cancelled': False, 'headers': {}}, 'response': {'took': 116, 'timed_out': False, 'total': 12, 'updated': 0, 'created': 12, 'deleted': 0, 'batches': 1, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled': '0s', 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until': '0s', 'throttled_until_millis': 0, 'failures': []}})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect a new document to confirm that it now has an `\"ml\": {\"tokens\":...}` field that contains a list of new, additional terms.\n",
        "These terms are the **text expansion** of the field(s) you targeted for ELSER inference.\n",
        "ELSER essentially creates a tree of expanded terms to improve the semantic searchability of your documents.\n",
        "We'll be able to search these documents using a `text_expansion` query.\n",
        "\n",
        "But first let's start with a simpler, classical search strategy. We'll then use progressively more sophisticated approaches, and compare the results.\n"
      ],
      "metadata": {
        "id": "oCj3jHHML4Tn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keyword match\n",
        "\n",
        "## Successful match\n",
        "\n",
        "Let's start by assuming a user queries the data set and hits an exact match.\n",
        "BM25 is perfect for exact keyword matches.\n",
        "Imagine our user remembers a movie where a child's spinning top was a recurring image.\n",
        "They search for `spinning top` and because these exact words are used in the key scene description, we get a perfect hit.\n"
      ],
      "metadata": {
        "id": "_KahQAbPPd9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"elser-movies\",\n",
        "    query= {\n",
        "            \"match\": {\n",
        "                \"keyScene\": \"spinning top\"\n",
        "            }\n",
        "        }\n",
        ")\n",
        "for hit in response['hits']['hits']:\n",
        "    doc_id = hit['_id']\n",
        "    score = hit['_score']\n",
        "    title = hit['_source']['title']\n",
        "    text = hit['_source']['keyScene']\n",
        "    print(f\"\\nTitle: {title}\\nKey scene description: {text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsZkFhGaYnzD",
        "outputId": "843c72f1-6a0c-43ce-c1e4-ad5e763ebc95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Title: Inception\n",
            "Key scene description: Leonardo DiCaprio explains the concept of inception to Ellen Page by using a child's spinning top.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsuccessful match\n",
        "\n",
        "Unfortunately, searches that rely on exact matches are brittle.\n",
        "What if you can't remember the exact name of the thing you're searching for?\n",
        "Who knows what a spinning top is anyway?\n",
        "\n",
        "Imagine I can only think of the word `child toy` to describe this apparatus?\n",
        "A match query won't find any relevant documents."
      ],
      "metadata": {
        "id": "Y01WHeOtbTZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(\n",
        "    index=\"elser-movies\",\n",
        "    query= {\n",
        "            \"match\": {\n",
        "                \"keyScene\": \"child toy\"\n",
        "            }\n",
        "        }\n",
        ")\n",
        "hits = response['hits']['hits']\n",
        "\n",
        "if not hits:\n",
        "    print(\"No matches found\")\n",
        "else:\n",
        "    for hit in hits:\n",
        "        doc_id = hit['_id']\n",
        "        score = hit['_score']\n",
        "        title = hit['_source']['title']\n",
        "        text = hit['_source']['keyScene']\n",
        "        print(f\"\\nTitle: {title}\\nKey scene description: {text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osifkhqidjYw",
        "outputId": "6b917df6-b0af-4947-9280-98f7b17f2ff9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No matches found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it turns out classical term matching strategies are very good, if you know precisely what you're looking for.\n",
        "But they break down when a user has a hard time articulating what they're trying to find.\n",
        "Here's where semantic search shines.\n",
        "It helps capture a user's intent or meaning better, without relying on brittle term matches.\n",
        "\n",
        "Traditional dense vector based similarity strategies require you to generate embeddings for your data and then map queries into the same mathematical space as the data.\n",
        "This works well but is time consuming and requires a lot of legwork.\n",
        "The beauty of the Elastic Learned Sparse Encoder model is that it works out-of-the-box, without the need to fine tune on your data.\n",
        "\n",
        "The Elastic Learned Sparse Encoder creates a tree of expanded terms, adds them to your documents, improving their semantic searchability.\n",
        "The fields that you targeted for inference are now enriched with a range of relevant synonyms and related terms, that increase the probability of a successful search."
      ],
      "metadata": {
        "id": "MPCVztOLeAk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic search with the `text_expansion` query\n",
        "\n",
        "Let's test out semantic search using the Elastic Learned Sparse Encoder, and see if we can improve our earlier unsuccessful search, using the query `child toy`.\n",
        "\n",
        "To perform semantic search using the Elastic Learned Sparse Encoder, you need the following:\n",
        "- A `text_expansion` query\n",
        "- Query text\n",
        "   - In this example we use `child toy`\n",
        "- ELSER model ID"
      ],
      "metadata": {
        "id": "Zy5GT2xb38oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.search(index='elser-movies',\n",
        "              query={\n",
        "                  \"text_expansion\": {\n",
        "                  \"ml.tokens\": {\n",
        "                      \"model_id\":\".elser_model_1\",\n",
        "                      \"model_text\":\"child toy\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        ")\n",
        "\n",
        "for hit in response['hits']['hits']:\n",
        "    doc_id = hit['_id']\n",
        "    score = hit['_score']\n",
        "    title = hit['_source']['title']\n",
        "    text = hit['_source']['keyScene']\n",
        "    print(f\"Score: {score}\\nTitle: {title}\\nKey scene description: {text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAZRxja-5Q6X",
        "outputId": "37a26a2c-4284-4e51-c34e-9a55edf77cb8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 4.2151423\n",
            "Title: Inception\n",
            "Key scene description: Leonardo DiCaprio explains the concept of inception to Ellen Page by using a child's spinning top.\n",
            "\n",
            "Score: 0.81614393\n",
            "Title: The Silence of the Lambs\n",
            "Key scene description: Hannibal Lecter explains to Clarice Starling that he ate a census taker's liver with some fava beans and a nice Chianti.\n",
            "\n",
            "Score: 0.25954634\n",
            "Title: Goodfellas\n",
            "Key scene description: Joe Pesci's character Tommy DeVito shoots young Spider in the foot for not getting him a drink.\n",
            "\n",
            "Score: 0.012798682\n",
            "Title: The Dark Knight\n",
            "Key scene description: Batman angrily responds 'I‚Äôm Batman' when asked who he is by Falcone.\n",
            "\n",
            "Score: 0.011333982\n",
            "Title: The Shawshank Redemption\n",
            "Key scene description: Andy Dufresne escapes from Shawshank prison by crawling through a sewer pipe.\n",
            "\n",
            "Score: 0.008927691\n",
            "Title: The Usual Suspects\n",
            "Key scene description: Kevin Spacey's character Verbal Kint is revealed to be the mastermind behind the crime, when his limp disappears as he walks away from the police station.\n",
            "\n",
            "Score: 0.0064342148\n",
            "Title: The Godfather\n",
            "Key scene description: James Caan's character Sonny Corleone is shot to death at a toll booth by a number of machine gun toting enemies.\n",
            "\n",
            "Score: 0.0034350685\n",
            "Title: The Departed\n",
            "Key scene description: Leonardo DiCaprio's character Billy Costigan is shot to death by Matt Damon's character Colin Sullivan.\n",
            "\n",
            "Score: 0.0032868548\n",
            "Title: Fight Club\n",
            "Key scene description: Brad Pitt explains the rules of Fight Club to Edward Norton. The first rule of Fight Club is: You do not talk about Fight Club. The second rule of Fight Club is: You do not talk about Fight Club.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Success! Out of the box ELSER has taken a fuzzy, but semantically similar query and found the correct match.\n",
        "Our user has found the movie they're looking for!"
      ],
      "metadata": {
        "id": "yYSJ7fnv5uWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid search\n",
        "\n",
        "[Reciprocal Rank Fusion (RRF)](https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html) is a state-of-the-art ranking algorithm for combining results from different information retrieval strategies.\n",
        "RRF consistently improves the combined results of different search algorithms.\n",
        "It outperforms all other ranking algorithms, and often surpasses the best individual results, without calibration.\n",
        "\n",
        "Combine `text_expansion` with other queries in a [compound query](https://www.elastic.co/guide/en/elasticsearch/reference/8.8/compound-queries.html).\n",
        "For example, use a filter clause in a [Boolean](https://www.elastic.co/guide/en/elasticsearch/reference/8.8/query-dsl-bool-query.html), or a full text query which may or may not use the same query text as the `text_expansion` query. This enables you to combine the search results from both queries.\n",
        "\n",
        "Search hits from the `text_expansion` query tend to score higher than other Elasticsearch queries.\n",
        "Those scores can be regularized by adjusting the relevance scores of each query with the `boost` parameter.\n",
        "Recall on the `text_expansion` query can be high where there is a long tail of less relevant results.\n",
        "Use the `min_score` parameter to prune those less relevant documents.\n",
        "\n",
        "‚ÑπÔ∏è Note the following about our example compound query:\n",
        "\n",
        "1. Both the `text_expansion` and the `query_string` queries are nested in a `should`\n",
        "clause of a `bool` query.\n",
        "2. The `text_expansion` query's boost value is set to the default of `1`.\n",
        "This means that relevance scores for this query's results are not boosted.\n",
        "3. The `boost` value for the `query_string` query is `4`.\n",
        "This query's results have a higher relevance score, which means higher search rankings.\n",
        "4. Only the results with a score equal to or higher than `10` are displayed."
      ],
      "metadata": {
        "id": "MrBCHdH1u8Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combo = client.search(\n",
        "    index='elser-movies', query= {\n",
        "            \"bool\": {\n",
        "                \"should\": [\n",
        "                    {\n",
        "                        \"text_expansion\": {\n",
        "                            \"ml.tokens\": {\n",
        "                                \"model_text\": \"who walked funny?\",\n",
        "                                \"model_id\": \".elser_model_1\",\n",
        "                                \"boost\": 1\n",
        "                            }\n",
        "                        }\n",
        "                    },\n",
        "                    {\n",
        "                        \"query_string\": {\n",
        "                            \"query\": \"Kevin\",\n",
        "                            \"boost\": 4\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        },\n",
        "        min_score= 10\n",
        "\n",
        ")\n",
        "\n",
        "for hit in combo['hits']['hits']:\n",
        "    doc_id = hit['_id']\n",
        "    score = hit['_score']\n",
        "    text = hit['_source']['keyScene']\n",
        "    print(f\"Document ID: {doc_id}\\nScore: {score}\\nText: {text}\\n\")"
      ],
      "metadata": {
        "id": "kpSyyRsVvAxt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}