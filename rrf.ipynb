{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s49gpkvZ7q53"
   },
   "source": [
    "# Hybrid Search using RRF\n",
    "\n",
    "In this example we'll use the reciprocal rank fusion algorithm to combine the results of BM25 and kNN semantic search.\n",
    "We'll use the same dataset we used in our [quickstart](https://github.com/joemcelroy/elasticsearch-labs/blob/notebooks-guides/colab-notebooks-examples/search/00-quick-start.ipynb) guide.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Y01AXpELkygt"
   },
   "source": [
    "# 🧰 Requirements\n",
    "\n",
    "For this example, you will need:\n",
    "\n",
    "- Python 3.6 or later\n",
    "- An Elastic deployment with minimum **4GB machine learning node**\n",
    "   - We'll be using [Elastic Cloud](https://www.elastic.co/guide/en/cloud/current/ec-getting-started.html) for this example (available with a [free trial](https://cloud.elastic.co/registration?elektra=en-ess-sign-up-page))\n",
    "- The [ELSER](https://www.elastic.co/guide/en/machine-learning/8.8/ml-nlp-elser.html) model installed on your Elastic deployment\n",
    "- The [Elastic Python client](https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/installation.html)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "N4pI1-eIvWrI"
   },
   "source": [
    "# Create Elastic Cloud deployment\n",
    "\n",
    "If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?fromURI=%2Fhome) for a free trial.\n",
    "\n",
    "- Go to the [Create deployment](https://cloud.elastic.co/deployments/create) page\n",
    "   - Under **Advanced settings**, go to **Machine Learning instances**\n",
    "   - You'll need at least **4GB** RAM per zone for this tutorial\n",
    "   - Select **Create deployment**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gaTFHLJC-Mgi"
   },
   "source": [
    "# Install packages and initialize the Elasticsearch Python client\n",
    "\n",
    "To get started, we'll need to connect to our Elastic deployment using the Python client.\n",
    "Because we're using an Elastic Cloud deployment, we'll use the **Cloud ID** to identify our deployment.\n",
    "\n",
    "First we need to `pip` install the following packages:\n",
    "\n",
    "- `elasticsearch`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9Q1p2C9-wce",
    "outputId": "204d5aee-571e-4363-be6e-f87d058f2d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Obtaining elasticsearch from git+https://github.com/elastic/elasticsearch-py.git@v8.8.2#egg=elasticsearch\n",
      "  Updating ./src/elasticsearch clone (to revision v8.8.2)\n",
      "  Running command git fetch -q --tags\n",
      "  Running command git reset --hard -q ec28599ac3ad1848f7c9d24cfad6f64cf8dc36ed\n",
      "Requirement already satisfied: elastic-transport<9,>=8 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from elasticsearch) (8.4.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.26.2 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch) (1.26.16)\n",
      "Requirement already satisfied: certifi in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from elastic-transport<9,>=8->elasticsearch) (2023.5.7)\n",
      "Installing collected packages: elasticsearch\n",
      "  Attempting uninstall: elasticsearch\n",
      "    Found existing installation: elasticsearch 8.8.2\n",
      "    Uninstalling elasticsearch-8.8.2:\n",
      "      Successfully uninstalled elasticsearch-8.8.2\n",
      "  Running setup.py develop for elasticsearch\n",
      "Successfully installed elasticsearch-8.8.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/liamthompson/.pyenv/versions/3.9.7/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentence_transformers in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: numpy in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (1.25.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sentence_transformers) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.6.3)\n",
      "Requirement already satisfied: requests in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: fsspec in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: sympy in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: click in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torchvision->sentence_transformers) (10.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/liamthompson/.pyenv/versions/3.9.7/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: networkx in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: filelock in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: jinja2 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: typing-extensions in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/liamthompson/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Users/liamthompson/.pyenv/versions/3.9.7/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e git+https://github.com/elastic/elasticsearch-py.git@v8.8.2#egg=elasticsearch\n",
    "!pip install sentence_transformers\n",
    "!pip install torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzq2Z1wBs3M"
   },
   "source": [
    "[TODO: Update]\n",
    "Next we need to import the `elasticsearch` module and the `getpass` module.\n",
    "`getpass` is part of the Python standard library and is used to securely prompt for credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "uP_GTVRi-d96"
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "from urllib.request import urlopen\n",
    "import getpass\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AMSePFiZCRqX"
   },
   "source": [
    "Now we can instantiate the Python Elasticsearch client.\n",
    "First we prompt the user for their password and Cloud ID.\n",
    "\n",
    "🔐 NOTE: `getpass` enables us to securely prompt the user for credentials without echoing them to the terminal, or storing it in memory.\n",
    "\n",
    "Then we create a `client` object that instantiates an instance of the `Elasticsearch` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h0MdAZ53CdKL",
    "outputId": "96ea6f81-f935-4d51-c4a7-af5a896180f1"
   },
   "outputs": [],
   "source": [
    "# Found in the 'Manage Deployment' page\n",
    "CLOUD_ID = getpass.getpass('Enter Elastic Cloud ID:  ')\n",
    "\n",
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = getpass.getpass('Enter Elastic password:  ')\n",
    "\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    cloud_id=CLOUD_ID,\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "bRHbecNeEDL3"
   },
   "source": [
    "Confirm that the client has connected with this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdiUKqZbEKfF",
    "outputId": "43b6f1cd-a43e-4dbe-caa5-7fd170464881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'instance-0000000000', 'cluster_name': '9dd1e5c0b0d64796b8cf0746cf63d734', 'cluster_uuid': 'VeYvw6JhQcC3P-Q1-L9P_w', 'version': {'number': '8.9.0-SNAPSHOT', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'ac7d79178c3e57c935358453331efe9e9cc5104d', 'build_date': '2023-06-21T09:08:25.219504984Z', 'build_snapshot': True, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0', 'transport_version': '8500019'}, 'tagline': 'You Know, for Search'}\n"
     ]
    }
   ],
   "source": [
    "print(client.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "enHQuT57DhD1"
   },
   "source": [
    "Refer to https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect to a self-managed deployment.\n",
    "\n",
    "Read https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/connecting.html#connect-self-managed-new to learn how to connect using API keys.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TF_wxIAhD07a"
   },
   "source": [
    "# Create Elasticsearch index with required mappings\n",
    "\n",
    "We need to add a field to support dense vector storage and search.\n",
    "Note the `title_vector` field below, which is used to store the dense vector representation of the `title` field.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cvYECABJJs_2",
    "outputId": "18fb51e4-c4f6-4d1b-cb2d-bc6f8ec1aa84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/v2f6_x6s0kg51j2vbm5rlhww0000gn/T/ipykernel_2383/1628078329.py:22: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  client.indices.create(index='rrf_book_index', body=mapping)\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'resource_already_exists_exception', 'index [rrf_book_index/Ip8zitwhSMe0OJtEwpuqzQ] already exists')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 22\u001b[0m\n\u001b[1;32m      2\u001b[0m mapping \u001b[39m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmappings\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m      4\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mproperties\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     21\u001b[0m \u001b[39m# Create the index\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m client\u001b[39m.\u001b[39;49mindices\u001b[39m.\u001b[39;49mcreate(index\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrrf_book_index\u001b[39;49m\u001b[39m'\u001b[39;49m, body\u001b[39m=\u001b[39;49mmapping)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/elasticsearch/_sync/client/utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/elasticsearch/_sync/client/indices.py:517\u001b[0m, in \u001b[0;36mcreate\u001b[0;34m(self, index, aliases, error_trace, filter_path, human, mappings, master_timeout, pretty, settings, timeout, wait_for_active_shards)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/elasticsearch/_sync/client/_base.py:389\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mperform_request\u001b[39m(\n\u001b[1;32m    379\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    380\u001b[0m     method: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[39m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[39m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mperform_request(\n\u001b[1;32m    390\u001b[0m         method, path, params\u001b[39m=\u001b[39;49mparams, headers\u001b[39m=\u001b[39;49mheaders, body\u001b[39m=\u001b[39;49mbody\n\u001b[1;32m    391\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/elasticsearch/_sync/client/_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    318\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(meta\u001b[39m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    321\u001b[0m         message\u001b[39m=\u001b[39mmessage, meta\u001b[39m=\u001b[39mmeta, body\u001b[39m=\u001b[39mresp_body\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[39m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    326\u001b[0m     \u001b[39m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: BadRequestError(400, 'resource_already_exists_exception', 'index [rrf_book_index/Ip8zitwhSMe0OJtEwpuqzQ] already exists')"
     ]
    }
   ],
   "source": [
    "# Define the mapping\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\"},\n",
    "            \"authors\": {\"type\": \"keyword\"},\n",
    "            \"summary\": {\"type\": \"text\"},\n",
    "            \"publish_date\": {\"type\": \"date\"},\n",
    "            \"num_reviews\": {\"type\": \"integer\"},\n",
    "            \"publisher\": {\"type\": \"keyword\"},\n",
    "            \"title_vector\": { \n",
    "                \"type\": \"dense_vector\", \n",
    "                \"dims\": 384, \n",
    "                \"index\": \"true\", \n",
    "                \"similarity\": \"dot_product\" \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the index\n",
    "client.indices.create(index='rrf_book_index', body=mapping)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Let's index some data.\n",
    "Note that we are embedding the `title` field using the sentence transformer model.\n",
    "Once indexed, you'll see that your documents contain a `title_vector` field (`\"type\": \"dense_vector\"`) which contains a vector of floating point values.\n",
    "This is the embedding of the `title` field in vector space.\n",
    "We'll use this vector to perform semantic search using kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 29, 'errors': False, 'items': [{'index': {'_index': 'rrf_book_index', '_id': '7c-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 10, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '7s-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 11, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '78-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 12, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '8M-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 13, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '8c-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 14, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '8s-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 15, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '88-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 16, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '9M-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 17, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '9c-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 18, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': '9s-QKokBaD3r4jKCZkdN', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 19, '_primary_term': 1, 'status': 201}}]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = [\n",
    "    {\n",
    "        \"title\": \"The Pragmatic Programmer: Your Journey to Mastery\",\n",
    "        \"authors\": [\"andrew hunt\", \"david thomas\"],\n",
    "        \"summary\": \"A guide to pragmatic programming for software engineers and developers\",\n",
    "        \"publish_date\": \"2019-10-29\",\n",
    "        \"num_reviews\": 30,\n",
    "        \"publisher\": \"addison-wesley\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Python Crash Course\",\n",
    "        \"authors\": [\"eric matthes\"],\n",
    "        \"summary\": \"A fast-paced, no-nonsense guide to programming in Python\",\n",
    "        \"publish_date\": \"2019-05-03\",\n",
    "        \"num_reviews\": 42,\n",
    "        \"publisher\": \"no starch press\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Artificial Intelligence: A Modern Approach\",\n",
    "        \"authors\": [\"stuart russell\", \"peter norvig\"],\n",
    "        \"summary\": \"Comprehensive introduction to the theory and practice of artificial intelligence\",\n",
    "        \"publish_date\": \"2020-04-06\",\n",
    "        \"num_reviews\": 39,\n",
    "        \"publisher\": \"pearson\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Clean Code: A Handbook of Agile Software Craftsmanship\",\n",
    "        \"authors\": [\"robert c. martin\"],\n",
    "        \"summary\": \"A guide to writing code that is easy to read, understand and maintain\",\n",
    "        \"publish_date\": \"2008-08-11\",\n",
    "        \"num_reviews\": 55,\n",
    "        \"publisher\": \"prentice hall\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"You Don't Know JS: Up & Going\",\n",
    "        \"authors\": [\"kyle simpson\"],\n",
    "        \"summary\": \"Introduction to JavaScript and programming as a whole\",\n",
    "        \"publish_date\": \"2015-03-27\",\n",
    "        \"num_reviews\": 36,\n",
    "        \"publisher\": \"oreilly\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Eloquent JavaScript\",\n",
    "        \"authors\": [\"marijn haverbeke\"],\n",
    "        \"summary\": \"A modern introduction to programming\",\n",
    "        \"publish_date\": \"2018-12-04\",\n",
    "        \"num_reviews\": 38,\n",
    "        \"publisher\": \"no starch press\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Design Patterns: Elements of Reusable Object-Oriented Software\",\n",
    "        \"authors\": [\"erich gamma\", \"richard helm\", \"ralph johnson\", \"john vlissides\"],\n",
    "        \"summary\": \"Guide to design patterns that can be used in any object-oriented language\",\n",
    "        \"publish_date\": \"1994-10-31\",\n",
    "        \"num_reviews\": 45,\n",
    "        \"publisher\": \"addison-wesley\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Clean Coder: A Code of Conduct for Professional Programmers\",\n",
    "        \"authors\": [\"robert c. martin\"],\n",
    "        \"summary\": \"A guide to professional conduct in the field of software engineering\",\n",
    "        \"publish_date\": \"2011-05-13\",\n",
    "        \"num_reviews\": 20,\n",
    "        \"publisher\": \"prentice hall\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"JavaScript: The Good Parts\",\n",
    "        \"authors\": [\"douglas crockford\"],\n",
    "        \"summary\": \"A deep dive into the parts of JavaScript that are essential to writing maintainable code\",\n",
    "        \"publish_date\": \"2008-05-15\",\n",
    "        \"num_reviews\": 51,\n",
    "        \"publisher\": \"oreilly\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Introduction to the Theory of Computation\",\n",
    "        \"authors\": [\"michael sipser\"],\n",
    "        \"summary\": \"Introduction to the theory of computation and complexity theory\",\n",
    "        \"publish_date\": \"2012-06-27\",\n",
    "        \"num_reviews\": 33,\n",
    "        \"publisher\": \"cengage learning\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index documents\n",
    "\n",
    "Our dataset is a Python list that contains dictionaries of movie titles and descriptions.\n",
    "We'll use the `helpers.bulk` method to index our documents in batches.\n",
    "\n",
    "The following code iterates over the list of books and creates a list of actions to be performed.\n",
    "Each action is a dictionary containing an \"index\" operation on our Elasticsearch index.\n",
    "The book's title is encoded using our selected model, and the encoded vector is added to the book document.\n",
    "The book document is then added to the list of actions.\n",
    "\n",
    "Finally, we call the `bulk` method, specifying the index name and the list of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 26, 'errors': False, 'items': [{'index': {'_index': 'rrf_book_index', '_id': 'HM-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 20, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Hc-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 21, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Hs-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 22, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'H8-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 23, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'IM-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 24, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Ic-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 25, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Is-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 26, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'I8-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 27, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'JM-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 28, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'rrf_book_index', '_id': 'Jc-NK4kBaD3r4jKCb0iX', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 29, '_primary_term': 1, 'status': 201}}]})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = []\n",
    "for book in books:\n",
    "    actions.append({\"index\": {\"_index\": \"rrf_book_index\"}})\n",
    "    titleEmbedding = model.encode(book[\"title\"]).tolist()\n",
    "    book[\"title_vector\"] = titleEmbedding\n",
    "    actions.append(book)\n",
    "\n",
    "client.bulk(index=\"rrf_book_index\", operations=actions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WgWDMgf9NkHL"
   },
   "source": [
    "## Pretty printing Elasticsearch responses\n",
    "\n",
    "This is a helper function to print Elasticsearch responses in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_response(response):\n",
    "    for hit in response['hits']['hits']:\n",
    "        id = hit['_id']\n",
    "        publication_date = hit['_source']['publish_date']\n",
    "        score = hit['_score']\n",
    "        title = hit['_source']['title']\n",
    "        summary = hit['_source']['summary']\n",
    "        pretty_output = (f\"\\nID: {id}\\nPublication date: {publication_date}\\nTitle: {title}\\nSummary: {summary}\\nScore: {score}\")\n",
    "        print(pretty_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MrBCHdH1u8Wd"
   },
   "source": [
    "# Hybrid search using RRF\n",
    "\n",
    "\n",
    "[Reciprocal Rank Fusion (RRF)](https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html) is a state-of-the-art ranking algorithm for combining results from different information retrieval strategies.\n",
    "RRF consistently improves the combined results of different search algorithms.\n",
    "It outperforms all other ranking algorithms, and often surpasses the best individual results, without calibration.\n",
    "\n",
    "⛔️ Because RRF is not yet available in the Python client, we'll use the `requests` library to make the request.⛔️ \n",
    "\n",
    "Check out the [RRF API reference](https://www.elastic.co/guide/en/elasticsearch/reference/master/rrf.html#rrf-api) for more information.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "kpSyyRsVvAxt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ID: EuRpJYkBM7k8MFjPzXnU\n",
      "Publication date: 2019-05-03\n",
      "Title: Python Crash Course\n",
      "Summary: A fast-paced, no-nonsense guide to programming in Python\n",
      "Score: 0.8450546\n",
      "\n",
      "ID: 7s-QKokBaD3r4jKCZkdN\n",
      "Publication date: 2019-05-03\n",
      "Title: Python Crash Course\n",
      "Summary: A fast-paced, no-nonsense guide to programming in Python\n",
      "Score: 0.8450546\n",
      "\n",
      "ID: Hc-NK4kBaD3r4jKCb0iX\n",
      "Publication date: 2019-05-03\n",
      "Title: Python Crash Course\n",
      "Summary: A fast-paced, no-nonsense guide to programming in Python\n",
      "Score: 0.8450546\n",
      "\n",
      "ID: EeRpJYkBM7k8MFjPzXnU\n",
      "Publication date: 2019-10-29\n",
      "Title: The Pragmatic Programmer: Your Journey to Mastery\n",
      "Summary: A guide to pragmatic programming for software engineers and developers\n",
      "Score: 0.6832866\n",
      "\n",
      "ID: 7c-QKokBaD3r4jKCZkdN\n",
      "Publication date: 2019-10-29\n",
      "Title: The Pragmatic Programmer: Your Journey to Mastery\n",
      "Summary: A guide to pragmatic programming for software engineers and developers\n",
      "Score: 0.6832866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/v2f6_x6s0kg51j2vbm5rlhww0000gn/T/ipykernel_2383/1894029983.py:10: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = client.search(index=\"rrf_book_index\", body=body)\n"
     ]
    }
   ],
   "source": [
    "body = {\n",
    "    \"knn\": {\n",
    "        \"field\": \"title_vector\",\n",
    "        \"query_vector\" : model.encode(\"python programming\").tolist(),\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10},\n",
    "        \n",
    "}\n",
    "\n",
    "response = client.search(index=\"rrf_book_index\", body=body)\n",
    "\n",
    "pretty_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/v2f6_x6s0kg51j2vbm5rlhww0000gn/T/ipykernel_2383/1777345508.py:20: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  response = client.search(index=\"rrf_book_index\", body=body)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "search() got an unexpected keyword argument 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 20\u001b[0m\n\u001b[1;32m      1\u001b[0m body \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mterm\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49msearch(index\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrrf_book_index\u001b[39;49m\u001b[39m\"\u001b[39;49m, body\u001b[39m=\u001b[39;49mbody)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/elasticsearch/_sync/client/utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: search() got an unexpected keyword argument 'rank'"
     ]
    }
   ],
   "source": [
    "body = {\n",
    "    \"query\": {\n",
    "        \"term\": {\n",
    "            \"summary\": \"shoes\"\n",
    "        }\n",
    "    },\n",
    "    \"knn\": {\n",
    "        \"field\": \"title_vector\",\n",
    "        \"query_vector\" : model.encode(\"python programming\").tolist(),\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10},\n",
    "    \"rank\": {\n",
    "        \"rrf\": {\n",
    "            \"window_size\": 50,\n",
    "            \"rank_constant\": 20\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = client.search(index=\"rrf_book_index\", body=body)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
